{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec07e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script\n",
       "    src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js \">\n",
       "</script>\n",
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
       " } else {\n",
       "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\"\n",
       "    value=\"Click here to toggle on/off the raw code.\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import csv\n",
    "from figure_labeler import *\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<script\n",
    "    src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js \">\n",
    "</script>\n",
    "<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
    " } else {\n",
    "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\"\n",
    "    value=\"Click here to toggle on/off the raw code.\"></form>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55731ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = FigureLabeler();\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d05aba",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Using Pandas and SQL for EDA (SQL Version)</h1>\n",
    "<hr>\n",
    "\n",
    "<a name=\"top\"></a>\n",
    "#### Table of Contents:\n",
    "\n",
    "[ref0]: #exec_summary\n",
    "- [Executive Summary][ref0]\n",
    "\n",
    "[ref2]: #motiv\n",
    "- [Motivation][ref2]\n",
    "\n",
    "[ref3]: #dat_sor\n",
    "- [Data Source][ref3]\n",
    "\n",
    "[ref4]: #dat_prep\n",
    "- [Importing, Preprocessing, and EDA][ref4]\n",
    "\n",
    "[ref6]: #res_dis\n",
    "- [Conclusion][ref6]\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4c414",
   "metadata": {},
   "source": [
    "<a name=\"exec_summary\"></a>\n",
    "## Executive Summary\n",
    "***\n",
    "\n",
    "The objective is to demonstrate the combined use of Pandas and SQL for exploratory data analysis (EDA) through two separate Jupyter notebooks (ipynbs). One notebook will focus on Pandas while the other on SQL, showcasing their respective strengths in data manipulation and querying. The analysis will highlight how these tools can be seamlessly integrated to efficiently explore and gain insights from datasets, thereby providing a comprehensive understanding of the data's characteristics and patterns. This notebook will focus on the SQL Version.\n",
    "\n",
    "[ref]: #top\n",
    "[Back to Table of Contents][ref]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35088fcf",
   "metadata": {},
   "source": [
    "<a name=\"motiv\"></a>\n",
    "## Motivation\n",
    "***\n",
    "\n",
    "Motivated by the need for comprehensive exploratory data analysis (EDA) workflows, we aim to showcase the powerful synergy and similarities between two widely-used tools: Pandas and SQL. While Pandas excels in data manipulation and analysis within Python environments, SQL offers robust querying capabilities ideal for handling large datasets efficiently.\n",
    "\n",
    "[ref]: #top\n",
    "[Back to Table of Contents][ref]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c32a5",
   "metadata": {},
   "source": [
    "<a name=\"dat_sor\"></a>\n",
    "## Data Source\n",
    "***\n",
    "\n",
    "The dataset was taken from this link\n",
    "[Student Study Performance Dataset](https://www.kaggle.com/datasets/bhavikjikadara/student-study-performance)\n",
    "\n",
    "\n",
    "[ref]: #top\n",
    "[Back to Table of Contents][ref]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5532e2",
   "metadata": {},
   "source": [
    "<a name=\"dat_prep\"></a>\n",
    "## Importing, Preprocessing and EDA\n",
    "***\n",
    "\n",
    "In our SQL-based exploratory data analysis (EDA), we first imported the dataset into a SQL database management system using commands like CREATE TABLE and LOAD DATA, ensuring efficient storage and organization for analysis. Subsequently, we performed preprocessing tasks through SQL queries, including data cleaning, handling missing values, and ensuring data consistency. Leveraging SQL's querying capabilities, we conducted exploratory analysis by crafting queries involving aggregation functions like COUNT, SUM, and AVG to generate summary statistics for numerical attributes, while GROUP BY and ORDER BY clauses facilitated exploration of categorical variables. Throughout this process, we prioritized query optimization for performance and scalability, ensuring timely execution even with large datasets, and laying a robust foundation for subsequent analytical endeavors.\n",
    "\n",
    "[ref]: #top\n",
    "[Back to Table of Contents][ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9307f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successfully into SQLite database.\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS performance (\n",
    "    gender TEXT,\n",
    "    race_ethnicity TEXT,\n",
    "    parental_level_of_education TEXT,\n",
    "    lunch TEXT,\n",
    "    test_preparation_course TEXT,\n",
    "    math_score INTEGER,\n",
    "    reading_score INTEGER,\n",
    "    writing_score INTEGER\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "with open('study_performance.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip header row\n",
    "    for row in csv_reader:\n",
    "        cursor.execute(\"INSERT INTO performance VALUES (?, ?, ?, ?, ?, ?, ?, ?)\", row)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data imported successfully into SQLite database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c8760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('female', 'group B', \"bachelor's degree\", 'standard', 'none', 72, 72, 74)\n",
      "('female', 'group C', 'some college', 'standard', 'completed', 69, 90, 88)\n",
      "('female', 'group B', \"master's degree\", 'standard', 'none', 90, 95, 93)\n",
      "('male', 'group A', \"associate's degree\", 'free/reduced', 'none', 47, 57, 44)\n",
      "('male', 'group C', 'some college', 'standard', 'none', 76, 78, 75)\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor_head = conn.cursor()\n",
    "\n",
    "cursor_head.execute(\"SELECT * FROM performance LIMIT 5\")\n",
    "\n",
    "rows = cursor_head.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c8a3f",
   "metadata": {},
   "source": [
    "First 5 rows were printed from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb948f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cid                         name     type  notnull dflt_value  pk\n",
      "0    0                       gender     TEXT        0       None   0\n",
      "1    1               race_ethnicity     TEXT        0       None   0\n",
      "2    2  parental_level_of_education     TEXT        0       None   0\n",
      "3    3                        lunch     TEXT        0       None   0\n",
      "4    4      test_preparation_course     TEXT        0       None   0\n",
      "5    5                   math_score  INTEGER        0       None   0\n",
      "6    6                reading_score  INTEGER        0       None   0\n",
      "7    7                writing_score  INTEGER        0       None   0\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor_dtypes = conn.cursor()\n",
    "\n",
    "data_types_query = \"\"\"\n",
    "PRAGMA table_info(performance);\n",
    "\"\"\"\n",
    "\n",
    "cursor_dtypes.execute(data_types_query)\n",
    "\n",
    "data_types = cursor_dtypes.fetchall()\n",
    "\n",
    "columns = ['cid', 'name', 'type', 'notnull', 'dflt_value', 'pk']\n",
    "data_types_df = pd.DataFrame(data_types, columns=columns)\n",
    "print(data_types_df)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6bd932",
   "metadata": {},
   "source": [
    "Checking for Each type of data within the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a52fcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       math_score  reading_score  writing_score\n",
      "count  1000.00000    1000.000000    1000.000000\n",
      "mean     66.08900      69.169000      68.054000\n",
      "std      15.16308      14.600192      15.195657\n",
      "min       0.00000      17.000000      10.000000\n",
      "25%      57.00000      59.000000      57.750000\n",
      "50%      66.00000      70.000000      69.000000\n",
      "75%      77.00000      79.000000      79.000000\n",
      "max     100.00000     100.000000     100.000000\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor_sumstats = conn.cursor()\n",
    "\n",
    "cursor_sumstats.execute(\"\"\"\n",
    "SELECT * FROM performance;\n",
    "\"\"\")\n",
    "summary_stats = cursor_sumstats.fetchall()\n",
    "columns = [description[0] for description in cursor_sumstats.description]\n",
    "df = pd.DataFrame(summary_stats, columns=columns)\n",
    "print(df.describe())\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846e321",
   "metadata": {},
   "source": [
    "Describing the Data using df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c71ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female: 518\n",
      "male: 482\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor_gender_counts = conn.cursor()\n",
    "\n",
    "gender_counts_query = \"\"\"\n",
    "SELECT gender, COUNT(*) AS count\n",
    "FROM performance\n",
    "GROUP BY gender;\n",
    "\"\"\"\n",
    "\n",
    "cursor_gender_counts.execute(gender_counts_query)\n",
    "\n",
    "gender_counts = cursor_gender_counts.fetchall()\n",
    "\n",
    "for gender, count in gender_counts:\n",
    "    print(f\"{gender}: {count}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868baca6",
   "metadata": {},
   "source": [
    "Counts of Gender Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09af0bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group A: 89\n",
      "group B: 190\n",
      "group C: 319\n",
      "group D: 262\n",
      "group E: 140\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor_race_counts = conn.cursor()\n",
    "\n",
    "race_counts_query = \"\"\"\n",
    "SELECT race_ethnicity, COUNT(*) AS count\n",
    "FROM performance\n",
    "GROUP BY race_ethnicity;\n",
    "\"\"\"\n",
    "\n",
    "cursor_race_counts.execute(race_counts_query)\n",
    "\n",
    "race_counts = cursor_race_counts.fetchall()\n",
    "\n",
    "for race, count in race_counts:\n",
    "    print(f\"{race}: {count}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd3c73",
   "metadata": {},
   "source": [
    "Count of Ethnicity Groups of Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f03173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor_null = conn.cursor()\n",
    "\n",
    "table_schema_query = \"\"\"\n",
    "PRAGMA table_info(performance);\n",
    "\"\"\"\n",
    "cursor_null.execute(table_schema_query)\n",
    "\n",
    "table_schema = cursor_null.fetchall()\n",
    "\n",
    "missing_values_query = \"\"\"\n",
    "SELECT {}\n",
    "FROM performance;\n",
    "\"\"\"\n",
    "\n",
    "column_exprs = []\n",
    "for col in table_schema:\n",
    "    col_name = col[1]  \n",
    "    col_expr = f\"SUM(CASE WHEN {col_name} IS NULL THEN 1 ELSE 0 END) AS missing_{col_name}\"\n",
    "    column_exprs.append(col_expr)\n",
    "\n",
    "column_exprs_str = ', '.join(column_exprs)\n",
    "\n",
    "missing_values_query = missing_values_query.format(column_exprs_str)\n",
    "\n",
    "cursor_null.execute(missing_values_query)\n",
    "\n",
    "missing_values = cursor_null.fetchone()\n",
    "\n",
    "print(missing_values)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3fa62",
   "metadata": {},
   "source": [
    "No NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cb7abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in each column:\n",
      "gender: 2\n",
      "race_ethnicity: 5\n",
      "parental_level_of_education: 6\n",
      "lunch: 2\n",
      "test_preparation_course: 2\n",
      "math_score: 81\n",
      "reading_score: 72\n",
      "writing_score: 77\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('performance_data.db')\n",
    "cursor_nunique = conn.cursor()\n",
    "\n",
    "column_names_query = \"\"\"\n",
    "PRAGMA table_info(performance);\n",
    "\"\"\"\n",
    "\n",
    "cursor_nunique.execute(column_names_query)\n",
    "\n",
    "column_names = [row[1] for row in cursor_nunique.fetchall()]\n",
    "\n",
    "nunique_query = f\"\"\"\n",
    "SELECT {', '.join([f'COUNT(DISTINCT {col}) AS unique_{col}' for col in column_names])}\n",
    "FROM performance;\n",
    "\"\"\"\n",
    "\n",
    "cursor_nunique.execute(nunique_query)\n",
    "\n",
    "nunique_results = cursor_nunique.fetchone()\n",
    "\n",
    "print(\"Number of unique values in each column:\")\n",
    "for column, unique_count in zip(column_names, nunique_results):\n",
    "    print(f\"{column}: {unique_count}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42147712",
   "metadata": {},
   "source": [
    "Various Unique Values of our Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b573937",
   "metadata": {},
   "source": [
    "<a name=\"res_dis\"></a>\n",
    "## Conclusion\n",
    "***\n",
    "\n",
    "In conclusion, our SQL-based exploratory data analysis (EDA) has showcased the efficacy of leveraging SQL's querying capabilities for data import, preprocessing, and analysis tasks. By importing the dataset into a SQL database and executing queries to preprocess and explore the data, we have demonstrated SQL's versatility in handling various data manipulation tasks efficiently. Through aggregation functions and grouping operations, we obtained valuable insights into the dataset's characteristics and distributions, laying a solid foundation for further analytical endeavors. Moreover, our emphasis on query optimization underscores the importance of efficiency and scalability in handling large datasets. Overall, this SQL-driven EDA not only highlights the power of SQL as a tool for data analysis but also underscores its role in facilitating informed decision-making through comprehensive exploration of datasets.\n",
    "\n",
    "\n",
    "\n",
    "[ref]: #top\n",
    "[Back to Table of Contents][ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fcb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
